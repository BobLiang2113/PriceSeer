{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab592e2",
   "metadata": {},
   "source": [
    "# Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822655f",
   "metadata": {},
   "source": [
    "1. Enter your base URL, API key and model name you want to use in block \"Basic setting\", then run it.\n",
    "\n",
    "2. Select the basic data combination you wnat to use (raw, indicator, news and fake news), find the corresponding block and change the input and output path name to your own name in it.\n",
    "\n",
    "3. Run the block. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9e143",
   "metadata": {},
   "source": [
    "## Basic setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "BASE_URL = \"Enter your base url here\"\n",
    "API_KEY = \"Enter your api key here\"\n",
    "MODEL_NAME = \"Enter your model name here\"\n",
    "\n",
    "# initialize OpenAI client\n",
    "client = OpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    api_key=API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70026dd5",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input and output paths\n",
    "input_folder = \"raw_data\"\n",
    "output_file = \"raw_forecasts_claude-sonnet-4.5.csv\"\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "all_predictions = []\n",
    "\n",
    "for file_name in csv_files:\n",
    "    stock_name = os.path.splitext(file_name)[0]  # assume file name is stock name\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    print(f\"\\nüìà Processing {stock_name}...\")\n",
    "\n",
    "    try:\n",
    "        # read historical data\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        data_str = df.to_csv(index=False)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a financial data analyst.\n",
    "        You are given the past 1-year daily stock price data of {stock_name} in CSV format below.\n",
    "        Please perform the following tasks, do not include any explanations or extra text ‚Äî only output the CSV\n",
    "        \n",
    "        Tasks:\n",
    "        1. Analyze the trend and volatility of the data.\n",
    "        2. Predict the **closing price** of {stock_name} for 3, 5, and 10 trading days after the last date in the dataset, the exact dates are 2025/11/12, 2025/11/14, and 2025/11/21.\n",
    "        3. Return your predictions **strictly as a CSV table** with columns:\n",
    "           Date, Predicted_Close\n",
    "        4. Do not include any explanations or extra text ‚Äî only output the CSV.\n",
    "        \n",
    "        The data columns are:\n",
    "        - Date: Trading date\n",
    "        - Open: Opening price\n",
    "        - High: Highest price\n",
    "        - Low: Lowest price\n",
    "        - Close: Closing price\n",
    "        - Volume: Trading volume\n",
    "\n",
    "        Here is the historical data:\n",
    "        {data_str}\n",
    "        \"\"\"\n",
    "\n",
    "        # call the OpenAI API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"MODEL_NAME\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional financial analyst skilled in stock trend forecasting.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.4\n",
    "        )\n",
    "        csv_output = response.choices[0].message.content.strip()\n",
    "\n",
    "        try:\n",
    "            pred_df = pd.read_csv(io.StringIO(csv_output))\n",
    "            if not {\"Date\", \"Predicted_Close\"}.issubset(pred_df.columns):\n",
    "                raise ValueError(\"Missing required columns in GPT output.\")\n",
    "            pred_df[\"Stock\"] = stock_name \n",
    "            all_predictions.append(pred_df)\n",
    "            print(f\"‚úÖ {stock_name} prediction completed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} prediction failed: invalid CSV format. Error: {e}\")\n",
    "            print(\"Model output was:\\n\", csv_output[:300], \"...\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to process {stock_name}: {e}\")\n",
    "\n",
    "# combine all predictions and save to CSV\n",
    "if all_predictions:\n",
    "    final_df = pd.concat(all_predictions, ignore_index=True)\n",
    "    final_df = final_df[[\"Stock\", \"Date\", \"Predicted_Close\"]]\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n‚úÖ All forecasts saved to {output_file}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No valid forecasts generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12264c7",
   "metadata": {},
   "source": [
    "## Indicator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output paths\n",
    "input_folder = \"indicator_data\"\n",
    "output_file = \"indicator_forecasts_claude-sonnet-4.5_sub.csv\"\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "all_predictions = []\n",
    "\n",
    "def validate_prediction_result(csv_output, stock_name):\n",
    "    try:\n",
    "        lines = csv_output.split('\\n')\n",
    "        csv_lines = []\n",
    "        for line in lines:\n",
    "            if line.strip() and (line.startswith('Date') or (',' in line and not line.startswith('```'))):\n",
    "                csv_lines.append(line)\n",
    "        \n",
    "        if not csv_lines:\n",
    "            return None,\n",
    "        \n",
    "        clean_csv = '\\n'.join(csv_lines)\n",
    "        \n",
    "        pred_df = pd.read_csv(io.StringIO(clean_csv))\n",
    "        \n",
    "        # check number of columns\n",
    "        if not {\"Date\", \"Predicted_Close\"}.issubset(pred_df.columns):\n",
    "            if len(pred_df.columns) >= 2:\n",
    "                pred_df.columns = ['Date', 'Predicted_Close']\n",
    "            else:\n",
    "                return None, f\"Lack of columns, expect 2 columns, get {len(pred_df.columns)} columns\"\n",
    "        \n",
    "        # check number of rows\n",
    "        if len(pred_df) != 3:\n",
    "            return None, f\"Unexpected prediction number, expect 3, get {len(pred_df)}\"\n",
    "        \n",
    "        # check specific dates\n",
    "        expected_dates = ['2025/11/12', '2025/11/14', '2025/11/21']\n",
    "        actual_dates = pred_df['Date'].astype(str).tolist()\n",
    "        \n",
    "        if len(actual_dates) != 3:\n",
    "            return None, f\"Incorrect data number, expect 3, get {len(actual_dates)}\"\n",
    "        \n",
    "        pred_df[\"Stock\"] = stock_name\n",
    "        \n",
    "        return pred_df, \"Verified\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"CSV read failed: {e}\"\n",
    "\n",
    "def predict_stock_with_retry(client, stock_name, df, max_retries=3):\n",
    "    data_str = df.to_csv(index=False)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  Prediction attempt {attempt + 1}/{max_retries}\")\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            You are a financial data analyst.\n",
    "            You are given the past 1-year daily stock price data and financial indicators of {stock_name} in CSV format below.\n",
    "            Please perform the following tasks, do not include any explanations or extra text ‚Äî only output the CSV\n",
    "            \n",
    "            Tasks:\n",
    "            1. Analyze the trend and volatility of the data.\n",
    "            2. Predict the **closing price** of {stock_name} for 3, 5, and 10 trading days after the last date in the dataset, the exact dates are 2025/11/12, 2025/11/14, and 2025/11/21.\n",
    "            3. Return your predictions **strictly as a CSV table** with columns:\n",
    "               Date, Predicted_Close\n",
    "            4. Do not include any explanations or extra text ‚Äî only output the CSV.\n",
    "            \n",
    "            The primary data includes:\n",
    "            - Date: Trading date\n",
    "            - Open: Opening price\n",
    "            - High: Highest price\n",
    "            - Low: Lowest price\n",
    "            - Close: Closing price\n",
    "            - Volume: Trading volume\n",
    "            \n",
    "            The financial indicators are:\n",
    "            - Return: Daily return percentage\n",
    "            - LogReturn: Daily log return percentage\n",
    "            - SMA3, SMA5, SMA10, SMA30: 3, 5, 10, 30-day simple moving averages\n",
    "            - RSI: 14-day relative strength index\n",
    "            - MACD: Moving average convergence divergence\n",
    "            - MACD_Signal: MACD signal line\n",
    "            - BB-high, BB-low: Bollinger Bands high and low\n",
    "\n",
    "            Here is the historical data and financial indicators:\n",
    "            {data_str}\n",
    "            \"\"\"\n",
    "\n",
    "            # Call API\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"MODEL_NAME\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional financial analyst skilled in stock trend forecasting.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.4\n",
    "            )\n",
    "\n",
    "            # Get CSV output\n",
    "            csv_output = response.choices[0].message.content.strip()\n",
    "            print(f\"  API response length: {len(csv_output)}\")\n",
    "\n",
    "            pred_df, validation_msg = validate_prediction_result(csv_output, stock_name)\n",
    "            \n",
    "            if pred_df is not None:\n",
    "                print(f\"‚úÖ {stock_name} verification passed.\")\n",
    "                return pred_df\n",
    "            else:\n",
    "                print(csv_output)\n",
    "                print(f\"‚ö†Ô∏è {stock_name} verification failed: {validation_msg}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(\"  Retry waiting...\")\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    print(f\"üí• {stock_name} all retries failed\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} No. {attempt + 1} retry failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(f\"Find {len(csv_files)} stock files to process.\")\n",
    "\n",
    "# record processed and failed stocks\n",
    "processed_stocks = []\n",
    "failed_stocks = []\n",
    "\n",
    "for file_name in csv_files:\n",
    "    stock_name = os.path.splitext(file_name)[0]  # assume file name is stock name\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    print(f\"\\nüìà Processing {stock_name}...\")\n",
    "\n",
    "    try:\n",
    "        # read historical data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"  data shape: {df.shape}\")\n",
    "\n",
    "        # check data sufficiency\n",
    "        if len(df) < 10:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} no enough data, skipping\")\n",
    "            failed_stocks.append(stock_name)\n",
    "            continue\n",
    "\n",
    "        pred_df = predict_stock_with_retry(client, stock_name, df, max_retries=3)\n",
    "        \n",
    "        if pred_df is not None:\n",
    "            all_predictions.append(pred_df)\n",
    "            processed_stocks.append(stock_name)\n",
    "            print(f\"‚úÖ {stock_name} prediction success, prediction points: {len(pred_df)}\")\n",
    "        else:\n",
    "            print(f\"üí• {stock_name} prediction failed, skipping\")\n",
    "            failed_stocks.append(stock_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Process {stock_name} failed: {e}\")\n",
    "        failed_stocks.append(stock_name)\n",
    "    \n",
    "    # add delay between requests to avoid rate limits\n",
    "    time.sleep(2)\n",
    "\n",
    "# combine all predictions and save to CSV\n",
    "if all_predictions:\n",
    "    final_df = pd.concat(all_predictions, ignore_index=True)\n",
    "    final_df = final_df[[\"Stock\", \"Date\", \"Predicted_Close\"]]\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "\n",
    "    success_stocks = final_df['Stock'].nunique()\n",
    "    total_predictions = len(final_df)\n",
    "    \n",
    "    print(f\"\\nüéâ Prediction finished!\")\n",
    "    print(f\"‚úÖ Success prediction: {success_stocks}/{len(csv_files)} stocks\")\n",
    "    print(f\"üìä Total prediction number: {total_predictions} records\")\n",
    "    print(f\"üíæ Saved to: {output_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No valid forecasts generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d02b8c2",
   "metadata": {},
   "source": [
    "## News data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a90a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input and output paths\n",
    "input_folder = \"raw_data\"  # historical stock price data file folder\n",
    "news_folder = \"news_data\"  # news data file folder\n",
    "output_file = \"news_forecasts_claude_sub.csv\"\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "def load_news_data(stock_name):\n",
    "    \"\"\"load news data for the given stock\"\"\"\n",
    "    news_file = os.path.join(news_folder, f\"{stock_name}_news.csv\")\n",
    "    \n",
    "    if not os.path.exists(news_file):\n",
    "        print(f\"‚ö†Ô∏è Cannot find news file: {news_file}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        news_df = pd.read_csv(news_file)\n",
    "        print(f\"  Load news data: {len(news_df)} news\")\n",
    "        return news_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è read news file failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_news_for_prompt(news_df):\n",
    "    \"\"\"Convert news DataFrame to formatted string for prompt\"\"\"\n",
    "    if news_df is None or len(news_df) == 0:\n",
    "        return \"No relevant news data.\"\n",
    "    \n",
    "    news_content = []\n",
    "    for i, row in news_df.iterrows():\n",
    "        news_item = f\"News {i+1}:\\n\"\n",
    "        news_item += f\"Title: {row.get('title', 'N/A')}\\n\"\n",
    "        news_item += f\"Source: {row.get('source', 'N/A')}\\n\"\n",
    "        news_item += f\"Date: {row.get('date', 'N/A')}\\n\"\n",
    "        news_item += f\"Content: {row.get('content', 'N/A')}...\\n\"\n",
    "        news_item += \"-\" * 50\n",
    "        news_content.append(news_item)\n",
    "    \n",
    "    return \"\\n\".join(news_content)\n",
    "\n",
    "# retry mechanism for API requests\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def make_api_request(client, prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"MODEL_NAME\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional financial analyst skilled in stock trend forecasting.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.4,\n",
    "            timeout=60\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è API request failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_prediction_result(csv_output, stock_name):\n",
    "    try:\n",
    "        lines = csv_output.split('\\n')\n",
    "        csv_lines = []\n",
    "        for line in lines:\n",
    "            if line.strip() and (line.startswith('Date') or (',' in line and not line.startswith('```'))):\n",
    "                csv_lines.append(line)\n",
    "        \n",
    "        if not csv_lines:\n",
    "            return None,\n",
    "        \n",
    "        clean_csv = '\\n'.join(csv_lines)\n",
    "        \n",
    "        pred_df = pd.read_csv(io.StringIO(clean_csv))\n",
    "        \n",
    "        # check number of columns\n",
    "        if not {\"Date\", \"Predicted_Close\"}.issubset(pred_df.columns):\n",
    "            if len(pred_df.columns) >= 2:\n",
    "                pred_df.columns = ['Date', 'Predicted_Close']\n",
    "            else:\n",
    "                return None, f\"Lack of columns, expect 2 columns, get {len(pred_df.columns)} columns\"\n",
    "        \n",
    "        # check number of rows\n",
    "        if len(pred_df) != 3:\n",
    "            return None, f\"Unexpected prediction number, expect 3, get {len(pred_df)}\"\n",
    "        \n",
    "        # check specific dates\n",
    "        expected_dates = ['2025/11/12', '2025/11/14', '2025/11/21']\n",
    "        actual_dates = pred_df['Date'].astype(str).tolist()\n",
    "        \n",
    "        if len(actual_dates) != 3:\n",
    "            return None, f\"Incorrect data number, expect 3, get {len(actual_dates)}\"\n",
    "        \n",
    "        pred_df[\"Stock\"] = stock_name\n",
    "        \n",
    "        return pred_df, \"Verified\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"CSV read failed: {e}\"\n",
    "\n",
    "def predict_stock_with_retry(client, stock_name, df, news_content, max_retries=3):\n",
    "    \"\"\"Prediction function with retries\"\"\"\n",
    "    data_str = df.to_csv(index=False)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  Prediction attempt {attempt + 1}/{max_retries}\")\n",
    "            \n",
    "            # Prompt construction with news analysis\n",
    "            prompt = f\"\"\"\n",
    "            You are a financial data analyst.\n",
    "            You are given two types of data for {stock_name}:\n",
    "\n",
    "            1. PAST 1-YEAR STOCK PRICE DATA (in CSV format):\n",
    "            - Date: Trading date\n",
    "            - Open: Opening price\n",
    "            - High: Highest price\n",
    "            - Low: Lowest price\n",
    "            - Close: Closing price\n",
    "            - Volume: Trading volume\n",
    "\n",
    "            2. RECENT NEWS DATA:\n",
    "            {news_content}\n",
    "\n",
    "            TASKS:\n",
    "            1. Analyze both the historical price trend/volatility AND the information from recent news\n",
    "            2. Consider how the news might impact future stock performance\n",
    "            3. Predict the closing price of {stock_name} for 3, 5, and 10 trading days after the last date in the dataset\n",
    "               Exact prediction dates: 2025/11/12, 2025/11/14, 2025/11/21\n",
    "            4. Return your predictions strictly as a CSV table with columns:\n",
    "               Date, Predicted_Close\n",
    "\n",
    "            IMPORTANT:\n",
    "            - Combine both technical analysis (price data) and fundamental analysis (news)\n",
    "            - Do not include any explanations or extra text ‚Äî only output the CSV\n",
    "            - Ensure the output has exactly 3 rows for the 3 prediction dates\n",
    "            - Format must be valid CSV with headers: Date, Predicted_Close\n",
    "\n",
    "            HISTORICAL PRICE DATA:\n",
    "            {data_str}\n",
    "            \"\"\"\n",
    "\n",
    "            # Call API\n",
    "            response = make_api_request(client, prompt)\n",
    "            csv_output = response.choices[0].message.content.strip()\n",
    "            print(f\"  API response length: {len(csv_output)}\")\n",
    "\n",
    "            # Validate prediction result\n",
    "            pred_df, validation_msg = validate_prediction_result(csv_output, stock_name)\n",
    "            \n",
    "            if pred_df is not None:\n",
    "                print(f\"‚úÖ {stock_name} verification passed.\")\n",
    "                return pred_df\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è {stock_name} verification failed: {validation_msg}\")\n",
    "                print(csv_output)\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(\"  Waiting for retry...\")\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    print(f\"üí• {stock_name} all retries failed\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} No. {attempt + 1} attempt failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "print(f\"Find {len(csv_files)} stock files to process.\")\n",
    "\n",
    "# record processed and failed stocks\n",
    "processed_stocks = []\n",
    "failed_stocks = []\n",
    "\n",
    "for file_name in csv_files:\n",
    "    stock_name = os.path.splitext(file_name)[0]  # assume file name is stock name\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    print(f\"\\nüìà Processing {stock_name}...\")\n",
    "\n",
    "    try:\n",
    "        # read historical data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"  data shape: {df.shape}\")\n",
    "\n",
    "        # check data sufficiency\n",
    "        if len(df) < 10:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} no enough data, skipping\")\n",
    "            failed_stocks.append(stock_name)\n",
    "            continue\n",
    "\n",
    "        pred_df = predict_stock_with_retry(client, stock_name, df, max_retries=3)\n",
    "        \n",
    "        if pred_df is not None:\n",
    "            all_predictions.append(pred_df)\n",
    "            processed_stocks.append(stock_name)\n",
    "            print(f\"‚úÖ {stock_name} prediction success, prediction points: {len(pred_df)}\")\n",
    "        else:\n",
    "            print(f\"üí• {stock_name} prediction failed, skipping\")\n",
    "            failed_stocks.append(stock_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Process {stock_name} failed: {e}\")\n",
    "        failed_stocks.append(stock_name)\n",
    "    \n",
    "    # add delay between requests to avoid rate limits\n",
    "    time.sleep(2)\n",
    "\n",
    "# combine all predictions and save to CSV\n",
    "if all_predictions:\n",
    "    final_df = pd.concat(all_predictions, ignore_index=True)\n",
    "    final_df = final_df[[\"Stock\", \"Date\", \"Predicted_Close\"]]\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "\n",
    "    success_stocks = final_df['Stock'].nunique()\n",
    "    total_predictions = len(final_df)\n",
    "    \n",
    "    print(f\"\\nüéâ Prediction finished!\")\n",
    "    print(f\"‚úÖ Success prediction: {success_stocks}/{len(csv_files)} stocks\")\n",
    "    print(f\"üìä Total prediction number: {total_predictions} records\")\n",
    "    print(f\"üíæ Saved to: {output_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No valid forecasts generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617af02a",
   "metadata": {},
   "source": [
    "# Fake news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output paths\n",
    "input_folder = \"raw_data\"  # historical stock price data file folder\n",
    "news_folder = \"fake_news_data\"  # FAKE news data file folder\n",
    "output_file = \"fake_news_forecasts_claude.csv\"\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "def load_news_data(stock_name):\n",
    "    \"\"\"load news data for the given stock\"\"\"\n",
    "    news_file = os.path.join(news_folder, f\"{stock_name}_news.csv\")\n",
    "    \n",
    "    if not os.path.exists(news_file):\n",
    "        print(f\"‚ö†Ô∏è Cannot find news file: {news_file}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        news_df = pd.read_csv(news_file)\n",
    "        print(f\"  Load news data: {len(news_df)} news\")\n",
    "        return news_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è read news file failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_news_for_prompt(news_df):\n",
    "    \"\"\"Convert news DataFrame to formatted string for prompt\"\"\"\n",
    "    if news_df is None or len(news_df) == 0:\n",
    "        return \"No relevant news data.\"\n",
    "    \n",
    "    news_content = []\n",
    "    for i, row in news_df.iterrows():\n",
    "        news_item = f\"News {i+1}:\\n\"\n",
    "        news_item += f\"Title: {row.get('title', 'N/A')}\\n\"\n",
    "        news_item += f\"Source: {row.get('source', 'N/A')}\\n\"\n",
    "        news_item += f\"Date: {row.get('date', 'N/A')}\\n\"\n",
    "        news_item += f\"Content: {row.get('content', 'N/A')}...\\n\"\n",
    "        news_item += \"-\" * 50\n",
    "        news_content.append(news_item)\n",
    "    \n",
    "    return \"\\n\".join(news_content)\n",
    "\n",
    "# retry mechanism for API requests\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def make_api_request(client, prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"MODEL_NAME\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional financial analyst skilled in stock trend forecasting.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.4,\n",
    "            timeout=60\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è API request failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_prediction_result(csv_output, stock_name):\n",
    "    try:\n",
    "        lines = csv_output.split('\\n')\n",
    "        csv_lines = []\n",
    "        for line in lines:\n",
    "            if line.strip() and (line.startswith('Date') or (',' in line and not line.startswith('```'))):\n",
    "                csv_lines.append(line)\n",
    "        \n",
    "        if not csv_lines:\n",
    "            return None,\n",
    "        \n",
    "        clean_csv = '\\n'.join(csv_lines)\n",
    "        \n",
    "        pred_df = pd.read_csv(io.StringIO(clean_csv))\n",
    "        \n",
    "        # check number of columns\n",
    "        if not {\"Date\", \"Predicted_Close\"}.issubset(pred_df.columns):\n",
    "            if len(pred_df.columns) >= 2:\n",
    "                pred_df.columns = ['Date', 'Predicted_Close']\n",
    "            else:\n",
    "                return None, f\"Lack of columns, expect 2 columns, get {len(pred_df.columns)} columns\"\n",
    "        \n",
    "        # check number of rows\n",
    "        if len(pred_df) != 3:\n",
    "            return None, f\"Unexpected prediction number, expect 3, get {len(pred_df)}\"\n",
    "        \n",
    "        # check specific dates\n",
    "        expected_dates = ['2025/11/12', '2025/11/14', '2025/11/21']\n",
    "        actual_dates = pred_df['Date'].astype(str).tolist()\n",
    "        \n",
    "        if len(actual_dates) != 3:\n",
    "            return None, f\"Incorrect data number, expect 3, get {len(actual_dates)}\"\n",
    "        \n",
    "        pred_df[\"Stock\"] = stock_name\n",
    "        \n",
    "        return pred_df, \"Verified\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"CSV read failed: {e}\"\n",
    "\n",
    "def predict_stock_with_retry(client, stock_name, df, news_content, max_retries=3):\n",
    "    \"\"\"Prediction function with retries\"\"\"\n",
    "    data_str = df.to_csv(index=False)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  Prediction attempt {attempt + 1}/{max_retries}\")\n",
    "            \n",
    "            # Prompt construction with news analysis\n",
    "            prompt = f\"\"\"\n",
    "            You are a financial data analyst.\n",
    "            You are given two types of data for {stock_name}:\n",
    "\n",
    "            1. PAST 1-YEAR STOCK PRICE DATA (in CSV format):\n",
    "            - Date: Trading date\n",
    "            - Open: Opening price\n",
    "            - High: Highest price\n",
    "            - Low: Lowest price\n",
    "            - Close: Closing price\n",
    "            - Volume: Trading volume\n",
    "\n",
    "            2. RECENT NEWS DATA:\n",
    "            {news_content}\n",
    "\n",
    "            TASKS:\n",
    "            1. Analyze both the historical price trend/volatility AND the information from recent news\n",
    "            2. Consider how the news might impact future stock performance\n",
    "            3. Predict the closing price of {stock_name} for 3, 5, and 10 trading days after the last date in the dataset\n",
    "               Exact prediction dates: 2025/11/12, 2025/11/14, 2025/11/21\n",
    "            4. Return your predictions strictly as a CSV table with columns:\n",
    "               Date, Predicted_Close\n",
    "\n",
    "            IMPORTANT:\n",
    "            - Combine both technical analysis (price data) and fundamental analysis (news)\n",
    "            - Do not include any explanations or extra text ‚Äî only output the CSV\n",
    "            - Ensure the output has exactly 3 rows for the 3 prediction dates\n",
    "            - Format must be valid CSV with headers: Date, Predicted_Close\n",
    "\n",
    "            HISTORICAL PRICE DATA:\n",
    "            {data_str}\n",
    "            \"\"\"\n",
    "\n",
    "            # Call API\n",
    "            response = make_api_request(client, prompt)\n",
    "            csv_output = response.choices[0].message.content.strip()\n",
    "            print(f\"  API response length: {len(csv_output)}\")\n",
    "\n",
    "            # Validate prediction result\n",
    "            pred_df, validation_msg = validate_prediction_result(csv_output, stock_name)\n",
    "            \n",
    "            if pred_df is not None:\n",
    "                print(f\"‚úÖ {stock_name} verification passed.\")\n",
    "                return pred_df\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è {stock_name} verification failed: {validation_msg}\")\n",
    "                print(csv_output)\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(\"  Waiting for retry...\")\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    print(f\"üí• {stock_name} all retries failed\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} No. {attempt + 1} attempt failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "print(f\"Find {len(csv_files)} stock files to process.\")\n",
    "\n",
    "# record processed and failed stocks\n",
    "processed_stocks = []\n",
    "failed_stocks = []\n",
    "\n",
    "for file_name in csv_files:\n",
    "    stock_name = os.path.splitext(file_name)[0]  # assume file name is stock name\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    print(f\"\\nüìà Processing {stock_name}...\")\n",
    "\n",
    "    try:\n",
    "        # read historical data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"  data shape: {df.shape}\")\n",
    "\n",
    "        # check data sufficiency\n",
    "        if len(df) < 10:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} no enough data, skipping\")\n",
    "            failed_stocks.append(stock_name)\n",
    "            continue\n",
    "\n",
    "        pred_df = predict_stock_with_retry(client, stock_name, df, max_retries=3)\n",
    "        \n",
    "        if pred_df is not None:\n",
    "            all_predictions.append(pred_df)\n",
    "            processed_stocks.append(stock_name)\n",
    "            print(f\"‚úÖ {stock_name} prediction success, prediction points: {len(pred_df)}\")\n",
    "        else:\n",
    "            print(f\"üí• {stock_name} prediction failed, skipping\")\n",
    "            failed_stocks.append(stock_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Process {stock_name} failed: {e}\")\n",
    "        failed_stocks.append(stock_name)\n",
    "    \n",
    "    # add delay between requests to avoid rate limits\n",
    "    time.sleep(2)\n",
    "\n",
    "# combine all predictions and save to CSV\n",
    "if all_predictions:\n",
    "    final_df = pd.concat(all_predictions, ignore_index=True)\n",
    "    final_df = final_df[[\"Stock\", \"Date\", \"Predicted_Close\"]]\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "\n",
    "    success_stocks = final_df['Stock'].nunique()\n",
    "    total_predictions = len(final_df)\n",
    "    \n",
    "    print(f\"\\nüéâ Prediction finished!\")\n",
    "    print(f\"‚úÖ Success prediction: {success_stocks}/{len(csv_files)} stocks\")\n",
    "    print(f\"üìä Total prediction number: {total_predictions} records\")\n",
    "    print(f\"üíæ Saved to: {output_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No valid forecasts generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197b669",
   "metadata": {},
   "source": [
    "# Raw + indicator + news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9addf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output paths\n",
    "input_folder = \"raw_data\"  # historical stock price data file folder\n",
    "news_folder = \"news_data\"  # news data file folder\n",
    "output_file = \"news_forecasts_claude.csv\"\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "all_predictions = []\n",
    "\n",
    "def load_news_data(stock_name):\n",
    "    \"\"\"Load news data for the given stock\"\"\"\n",
    "    news_file = os.path.join(news_folder, f\"{stock_name}_news.csv\")\n",
    "    \n",
    "    if not os.path.exists(news_file):\n",
    "        print(f\"‚ö†Ô∏è Cannot find news file: {news_file}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        news_df = pd.read_csv(news_file)\n",
    "        print(f\"  Load news data: {len(news_df)} news\")\n",
    "        return news_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Load news data failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_news_for_prompt(news_df):\n",
    "    \"\"\"Convert news DataFrame to formatted string for prompt\"\"\"\n",
    "    if news_df is None or len(news_df) == 0:\n",
    "        return \"No relevant news data.\"\n",
    "    \n",
    "    news_content = []\n",
    "    for i, row in news_df.iterrows():\n",
    "        news_item = f\"News {i+1}:\\n\"\n",
    "        news_item += f\"Title: {row.get('title', 'N/A')}\\n\"\n",
    "        news_item += f\"Sourch: {row.get('source', 'N/A')}\\n\"\n",
    "        news_item += f\"Date: {row.get('date', 'N/A')}\\n\"\n",
    "        news_item += f\"Content: {row.get('content', 'N/A')}...\\n\" \n",
    "        news_item += \"-\" * 50\n",
    "        news_content.append(news_item)\n",
    "    \n",
    "    return \"\\n\".join(news_content)\n",
    "\n",
    "# Retry mechanism for API requests\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def make_api_request(client, prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"MODEL_NAME\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional financial analyst skilled in stock trend forecasting.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.4,\n",
    "            timeout=60\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è API request failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "print(f\"Find {len(csv_files)} stock files to process.\")\n",
    "\n",
    "for file_name in csv_files:\n",
    "    stock_name = os.path.splitext(file_name)[0]  # assume file name is stock name\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    print(f\"\\nüìà Processing {stock_name}...\")\n",
    "\n",
    "    try:\n",
    "        # Load historical data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"  Stock data shape: {df.shape}\")\n",
    "\n",
    "        # Check data sufficiency\n",
    "        if len(df) < 10:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} data not sufficient, skipping\")\n",
    "            continue\n",
    "\n",
    "        # load and format news data\n",
    "        news_df = load_news_data(stock_name)\n",
    "        news_content = format_news_for_prompt(news_df)\n",
    "\n",
    "        data_str = df.to_csv(index=False)\n",
    "\n",
    "        # Prompt construction with indicator and news analysis\n",
    "        prompt = f\"\"\"\n",
    "        You are a financial data analyst.\n",
    "        You are given 2 types of data for {stock_name}:\n",
    "\n",
    "        1. PAST 1-YEAR STOCK PRICE DATA and financial indicators (in CSV format):\n",
    "        - Date: Trading date\n",
    "        - Open: Opening price\n",
    "        - High: Highest price\n",
    "        - Low: Lowest price\n",
    "        - Close: Closing price\n",
    "        - Volume: Trading volume\n",
    "        \n",
    "        The financial indicators including:\n",
    "        - Return: Daily return percentage\n",
    "        - LogReturn: Daily log return percentage\n",
    "        - SMA3, SMA5, SMA10, SMA30: 3, 5, 10, 30-day simple moving averages\n",
    "        - RSI: 14-day relative strength index\n",
    "        - MACD: Moving average convergence divergence\n",
    "        - MACD_Signal: MACD signal line\n",
    "        - BB-high, BB-low: Bollinger Bands high and low\n",
    "        \n",
    "        2. RECENT NEWS DATA:\n",
    "        {news_content}\n",
    "\n",
    "        TASKS:\n",
    "        1. Analyze both the historical price trend/volatility AND the information from recent news\n",
    "        2. Consider how the news might impact future stock performance\n",
    "        3. Predict the closing price of {stock_name} for 3, 5, and 10 trading days after the last date in the dataset\n",
    "           Exact prediction dates: 2025/11/12, 2025/11/14, 2025/11/21\n",
    "        4. Return your predictions strictly as a CSV table with columns:\n",
    "           Date, Predicted_Close\n",
    "\n",
    "        IMPORTANT:\n",
    "        - Combine both technical analysis (price data) and fundamental analysis (news)\n",
    "        - Do not include any explanations or extra text ‚Äî only output the CSV\n",
    "        - Ensure the output has exactly 3 rows for the 3 prediction dates\n",
    "\n",
    "        HISTORICAL PRICE DATA:\n",
    "        {data_str}\n",
    "        \"\"\"\n",
    "\n",
    "        # Call API with retry\n",
    "        response = make_api_request(client, prompt)\n",
    "\n",
    "        # Get CSV output\n",
    "        csv_output = response.choices[0].message.content.strip()\n",
    "        print(f\"  API response length: {len(csv_output)}\")\n",
    "\n",
    "        try:\n",
    "            # clean and parse CSV output\n",
    "            lines = csv_output.split('\\n')\n",
    "            csv_lines = []\n",
    "            for line in lines:\n",
    "                if line.strip() and (line.startswith('Date') or ',' in line):\n",
    "                    csv_lines.append(line)\n",
    "            \n",
    "            clean_csv = '\\n'.join(csv_lines)\n",
    "            \n",
    "            pred_df = pd.read_csv(io.StringIO(clean_csv))\n",
    "            \n",
    "            # check columns\n",
    "            if not {\"Date\", \"Predicted_Close\"}.issubset(pred_df.columns):\n",
    "                if len(pred_df.columns) >= 2:\n",
    "                    pred_df.columns = ['Date', 'Predicted_Close']\n",
    "                else:\n",
    "                    raise ValueError(\"Missing required columns in GPT output.\")\n",
    "            \n",
    "            # check rows\n",
    "            if len(pred_df) != 3:\n",
    "                print(f\"‚ö†Ô∏è Unexpect prediction number: expect 3, get {len(pred_df)}\")\n",
    "                print(\"Model output was:\\n\", csv_output[:300], \"...\\n\")\n",
    "            \n",
    "            pred_df[\"Stock\"] = stock_name\n",
    "            all_predictions.append(pred_df)\n",
    "            print(f\"‚úÖ {stock_name} prediction success. Prediction points: {len(pred_df)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} prediction failed: {e}\")\n",
    "            print(\"Model output:\\n\", csv_output, \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå process {stock_name} failed: {e}\")\n",
    "\n",
    "    # add delay between requests to avoid rate limits\n",
    "    time.sleep(3)\n",
    "\n",
    "# combine all predictions and save to CSV\n",
    "if all_predictions:\n",
    "    final_df = pd.concat(all_predictions, ignore_index=True)\n",
    "    final_df = final_df[[\"Stock\", \"Date\", \"Predicted_Close\"]]\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n‚úÖ Finished predictino of {len(all_predictions)} stocks.\")\n",
    "    print(f\"‚úÖ All prediction saved to {output_file}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå No valid forecasts generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7516e4",
   "metadata": {},
   "source": [
    "# Raw + Indicator + Fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output paths\n",
    "input_folder = \"processed_data\"  # historical stock price data file folder\n",
    "news_folder = \"fake_news_data\"  # FAKE news data file folder\n",
    "output_file = \"fake_news_forecasts_claude.csv\"\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "all_predictions = []\n",
    "\n",
    "def load_news_data(stock_name):\n",
    "    \"\"\"Load news data for the given stock\"\"\"\n",
    "    news_file = os.path.join(news_folder, f\"{stock_name}_news.csv\")\n",
    "    \n",
    "    if not os.path.exists(news_file):\n",
    "        print(f\"‚ö†Ô∏è Cannot find news file: {news_file}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        news_df = pd.read_csv(news_file)\n",
    "        print(f\"  Load news data: {len(news_df)} news\")\n",
    "        return news_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Load news data failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_news_for_prompt(news_df):\n",
    "    \"\"\"Convert news DataFrame to formatted string for prompt\"\"\"\n",
    "    if news_df is None or len(news_df) == 0:\n",
    "        return \"No relevant news data.\"\n",
    "    \n",
    "    news_content = []\n",
    "    for i, row in news_df.iterrows():\n",
    "        news_item = f\"News {i+1}:\\n\"\n",
    "        news_item += f\"Title: {row.get('title', 'N/A')}\\n\"\n",
    "        news_item += f\"Sourch: {row.get('source', 'N/A')}\\n\"\n",
    "        news_item += f\"Date: {row.get('date', 'N/A')}\\n\"\n",
    "        news_item += f\"Content: {row.get('content', 'N/A')}...\\n\" \n",
    "        news_item += \"-\" * 50\n",
    "        news_content.append(news_item)\n",
    "    \n",
    "    return \"\\n\".join(news_content)\n",
    "\n",
    "# Retry mechanism for API requests\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def make_api_request(client, prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"MODEL_NAME\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional financial analyst skilled in stock trend forecasting.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.4,\n",
    "            timeout=60\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è API request failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "print(f\"Find {len(csv_files)} stock files to process.\")\n",
    "\n",
    "for file_name in csv_files:\n",
    "    stock_name = os.path.splitext(file_name)[0]  # assume file name is stock name\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    print(f\"\\nüìà Processing {stock_name}...\")\n",
    "\n",
    "    try:\n",
    "        # Load historical data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"  Stock data shape: {df.shape}\")\n",
    "\n",
    "        # Check data sufficiency\n",
    "        if len(df) < 10:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} data not sufficient, skipping\")\n",
    "            continue\n",
    "\n",
    "        # load and format news data\n",
    "        news_df = load_news_data(stock_name)\n",
    "        news_content = format_news_for_prompt(news_df)\n",
    "\n",
    "        data_str = df.to_csv(index=False)\n",
    "\n",
    "        # Prompt construction with indicator and news analysis\n",
    "        prompt = f\"\"\"\n",
    "        You are a financial data analyst.\n",
    "        You are given 2 types of data for {stock_name}:\n",
    "\n",
    "        1. PAST 1-YEAR STOCK PRICE DATA and financial indicators (in CSV format):\n",
    "        - Date: Trading date\n",
    "        - Open: Opening price\n",
    "        - High: Highest price\n",
    "        - Low: Lowest price\n",
    "        - Close: Closing price\n",
    "        - Volume: Trading volume\n",
    "        \n",
    "        The financial indicators including:\n",
    "        - Return: Daily return percentage\n",
    "        - LogReturn: Daily log return percentage\n",
    "        - SMA3, SMA5, SMA10, SMA30: 3, 5, 10, 30-day simple moving averages\n",
    "        - RSI: 14-day relative strength index\n",
    "        - MACD: Moving average convergence divergence\n",
    "        - MACD_Signal: MACD signal line\n",
    "        - BB-high, BB-low: Bollinger Bands high and low\n",
    "        \n",
    "        2. RECENT NEWS DATA:\n",
    "        {news_content}\n",
    "\n",
    "        TASKS:\n",
    "        1. Analyze both the historical price trend/volatility AND the information from recent news\n",
    "        2. Consider how the news might impact future stock performance\n",
    "        3. Predict the closing price of {stock_name} for 3, 5, and 10 trading days after the last date in the dataset\n",
    "           Exact prediction dates: 2025/11/12, 2025/11/14, 2025/11/21\n",
    "        4. Return your predictions strictly as a CSV table with columns:\n",
    "           Date, Predicted_Close\n",
    "\n",
    "        IMPORTANT:\n",
    "        - Combine both technical analysis (price data) and fundamental analysis (news)\n",
    "        - Do not include any explanations or extra text ‚Äî only output the CSV\n",
    "        - Ensure the output has exactly 3 rows for the 3 prediction dates\n",
    "\n",
    "        HISTORICAL PRICE DATA:\n",
    "        {data_str}\n",
    "        \"\"\"\n",
    "\n",
    "        # Call API with retry\n",
    "        response = make_api_request(client, prompt)\n",
    "\n",
    "        # Get CSV output\n",
    "        csv_output = response.choices[0].message.content.strip()\n",
    "        print(f\"  API response length: {len(csv_output)}\")\n",
    "\n",
    "        try:\n",
    "            # clean and parse CSV output\n",
    "            lines = csv_output.split('\\n')\n",
    "            csv_lines = []\n",
    "            for line in lines:\n",
    "                if line.strip() and (line.startswith('Date') or ',' in line):\n",
    "                    csv_lines.append(line)\n",
    "            \n",
    "            clean_csv = '\\n'.join(csv_lines)\n",
    "            \n",
    "            pred_df = pd.read_csv(io.StringIO(clean_csv))\n",
    "            \n",
    "            # check columns\n",
    "            if not {\"Date\", \"Predicted_Close\"}.issubset(pred_df.columns):\n",
    "                if len(pred_df.columns) >= 2:\n",
    "                    pred_df.columns = ['Date', 'Predicted_Close']\n",
    "                else:\n",
    "                    raise ValueError(\"Missing required columns in GPT output.\")\n",
    "            \n",
    "            # check rows\n",
    "            if len(pred_df) != 3:\n",
    "                print(f\"‚ö†Ô∏è Unexpect prediction number: expect 3, get {len(pred_df)}\")\n",
    "                print(\"Model output was:\\n\", csv_output[:300], \"...\\n\")\n",
    "            \n",
    "            pred_df[\"Stock\"] = stock_name\n",
    "            all_predictions.append(pred_df)\n",
    "            print(f\"‚úÖ {stock_name} prediction success. Prediction points: {len(pred_df)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è {stock_name} prediction failed: {e}\")\n",
    "            print(\"Model output:\\n\", csv_output, \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå process {stock_name} failed: {e}\")\n",
    "\n",
    "    # add delay between requests to avoid rate limits\n",
    "    time.sleep(3)\n",
    "\n",
    "# combine all predictions and save to CSV\n",
    "if all_predictions:\n",
    "    final_df = pd.concat(all_predictions, ignore_index=True)\n",
    "    final_df = final_df[[\"Stock\", \"Date\", \"Predicted_Close\"]]\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n‚úÖ Finished predictino of {len(all_predictions)} stocks.\")\n",
    "    print(f\"‚úÖ All prediction saved to {output_file}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå No valid forecasts generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
